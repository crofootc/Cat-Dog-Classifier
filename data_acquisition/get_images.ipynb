{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SubredditPictureScraper as sps\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubredditPictureScraper instance created with values: sub = cats and days = 365\n",
      "SubredditPictureScraper instance created with values: sub = dogs and days = 365\n"
     ]
    }
   ],
   "source": [
    "Cats = sps.SubredditPictureScraper('cats', days=365)\n",
    "Dogs = sps.SubredditPictureScraper('dogs', days=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling all urls for last 365 days\n",
      "urls contains 271563 different urls\n",
      "Pulling all urls for last 365 days\n",
      "urls contains 682 different urls\n"
     ]
    }
   ],
   "source": [
    "Cats.update_image_urls()\n",
    "Dogs.update_image_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubredditPictureScraper instance created with values: sub = dogpictures and days = 365\n"
     ]
    }
   ],
   "source": [
    "# r/dogs apparently is not the best source for pictures, trying r/dogpictures instead\n",
    "Dogs = sps.SubredditPictureScraper('dogpictures', days=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling all urls for last 365 days\n",
      "urls contains 41188 different urls\n"
     ]
    }
   ],
   "source": [
    "# keeping track to see how long it takes\n",
    "start = time.time()\n",
    "Dogs.update_image_urls()\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 2.96 minutes\n",
      " 13894.18 urls per minute\n"
     ]
    }
   ],
   "source": [
    "print(f'total time: {(end-start)/60 :.2f} minutes')\n",
    "print(f'{(len(Dogs.get_urls()))/((end-start)/60) : .2f} urls per minute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving urls in text file \n",
    "Cats.save_url('cats.txt')\n",
    "Dogs.save_url('dogs.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving max of 5 images from urls\n",
      "MAKNG DIRECTORY: C:\\Users\\a01836024\\Documents\\GitHub\\ML1\\data_acquisition\\cat_example\n",
      "SAVING IMAGES\n",
      "BAD FILENAME\n",
      "Processed 5 images\n",
      "Saving max of 5 images from urls\n",
      "MAKNG DIRECTORY: C:\\Users\\a01836024\\Documents\\GitHub\\ML1\\data_acquisition\\dog_example\n",
      "SAVING IMAGES\n",
      "BAD FILENAME\n",
      "Processed 5 images\n"
     ]
    }
   ],
   "source": [
    "Cats.save_images(foldername='cat_example',image_limit=5)\n",
    "Dogs.save_images(foldername='dog_example',image_limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
